# Global Air Quality Forecasting System - Evaluation Framework

## Overview

This document outlines the comprehensive evaluation methodology for the Global 100-City Air Quality Forecasting System, focusing on both pollutant-specific predictions and composite Air Quality Index (AQI) performance across 11 regional standards.

---

## ðŸŽ¯ Evaluation Objectives

### Primary Goals
- **Health Warning Accuracy**: Minimize false negatives for public health protection
- **Local Standard Compliance**: Evaluate using appropriate regional AQI calculations
- **Cross-Continental Consistency**: Maintain evaluation standards across all 5 continents
- **Benchmark Comparison**: Demonstrate improvement over existing forecasting systems

### Success Criteria
- **Health Warning Recall**: >90% sensitivity for health alert detection
- **AQI Accuracy**: Correct category prediction in >80% of cases
- **Pollutant Prediction**: MAE reduction of >10% vs. best individual benchmark
- **False Negative Minimization**: <10% missed health warnings across all cities

---

## ðŸ”¬ Forecasting Models Under Evaluation

### Core Models (Phase 4 Implementation)
1. **Simple Average Ensemble**
   - Method: Arithmetic mean of two continental benchmarks
   - Purpose: Baseline ensemble performance
   - Implementation: Direct average of benchmark predictions

2. **Ridge Regression Ensemble**
   - Method: L2-regularized linear combination of benchmarks + features
   - Purpose: Optimized weighted ensemble with regularization
   - Features: Meteorological, temporal, and regional-specific variables

### Advanced Models (Future Implementation)
3. **Gradient Boosting Ensemble** *(Phase 5)*
   - Method: XGBoost/LightGBM with ensemble inputs
   - Purpose: Non-linear ensemble optimization
   - Features: Extended feature set with interaction terms

---

## ðŸ“Š Evaluation Metrics Framework

### 1. Individual Pollutant Performance

#### Core Pollutants (All Cities)
- **PM2.5**: Fine particulate matter (Î¼g/mÂ³)
- **PM10**: Coarse particulate matter (Î¼g/mÂ³)
- **NO2**: Nitrogen dioxide (Î¼g/mÂ³ or ppb)
- **O3**: Ozone (Î¼g/mÂ³ or ppb)
- **SO2**: Sulfur dioxide (Î¼g/mÂ³ or ppb) - where available

#### Pollutant-Specific Metrics
```
For each pollutant p in [PM2.5, PM10, NO2, O3, SO2]:
â”œâ”€â”€ Regression Metrics
â”‚   â”œâ”€â”€ Mean Absolute Error (MAE)
â”‚   â”œâ”€â”€ Root Mean Square Error (RMSE)
â”‚   â”œâ”€â”€ Mean Absolute Percentage Error (MAPE)
â”‚   â”œâ”€â”€ RÂ² Score (coefficient of determination)
â”‚   â””â”€â”€ Bias (mean prediction error)
â”œâ”€â”€ Distribution Metrics
â”‚   â”œâ”€â”€ Pearson correlation coefficient
â”‚   â”œâ”€â”€ Spearman rank correlation
â”‚   â””â”€â”€ Quantile analysis (P10, P25, P50, P75, P90)
â””â”€â”€ Threshold Performance
    â”œâ”€â”€ Exceedance detection (WHO/regional thresholds)
    â”œâ”€â”€ Precision/Recall for high pollution events
    â””â”€â”€ ROC-AUC for pollution level classification
```

### 2. Composite AQI Performance

#### Regional AQI Standards Evaluation
Each city evaluated using its designated local standard:

| Continent | AQI Standards Used | Scale | Categories |
|-----------|-------------------|-------|------------|
| **Europe** | European EAQI | 1-6 | Very Good â†’ Extremely Poor |
| **North America** | EPA AQI, Canadian AQHI, Mexican IMECA | 0-500+ | Good â†’ Hazardous |
| **Asia** | Indian, Chinese, Thai, Indonesian, Pakistani | 0-500+ | Good â†’ Severe+ |
| **Africa** | WHO Guidelines adaptation | Custom | Low â†’ Very High |
| **South America** | EPA adaptations, Chilean ICA | 0-500+ | Good â†’ Hazardous |

#### AQI-Specific Metrics
```
For each city's local AQI standard:
â”œâ”€â”€ Category Accuracy
â”‚   â”œâ”€â”€ Overall category prediction accuracy
â”‚   â”œâ”€â”€ Confusion matrix analysis
â”‚   â”œâ”€â”€ Per-category precision and recall
â”‚   â””â”€â”€ Weighted F1-score by category frequency
â”œâ”€â”€ Health Warning Performance
â”‚   â”œâ”€â”€ Sensitive Groups Alerts (Conservative thresholds)
â”‚   â”‚   â”œâ”€â”€ True Positive Rate (Sensitivity/Recall)
â”‚   â”‚   â”œâ”€â”€ False Positive Rate (1 - Specificity)
â”‚   â”‚   â”œâ”€â”€ Precision (Positive Predictive Value)
â”‚   â”‚   â””â”€â”€ False Negative Rate (CRITICAL METRIC)
â”‚   â””â”€â”€ General Population Alerts (Higher thresholds)
â”‚       â”œâ”€â”€ True Positive Rate
â”‚       â”œâ”€â”€ False Positive Rate
â”‚       â”œâ”€â”€ Precision
â”‚       â””â”€â”€ False Negative Rate
â”œâ”€â”€ Continuous AQI Metrics
â”‚   â”œâ”€â”€ AQI value MAE, RMSE, RÂ²
â”‚   â”œâ”€â”€ AQI value bias analysis
â”‚   â””â”€â”€ Extreme value prediction accuracy
â””â”€â”€ Dominant Pollutant Analysis
    â”œâ”€â”€ Dominant pollutant identification accuracy
    â”œâ”€â”€ Pollutant contribution analysis
    â””â”€â”€ Multi-pollutant event detection
```

### 3. Health Warning Analysis

#### False Positive Analysis
```
For each model M in [SimpleAverage, RidgeRegression]:
â””â”€â”€ False Positive Characterization
    â”œâ”€â”€ Rate: FP / (FP + TN)
    â”œâ”€â”€ Economic Impact: Unnecessary alert costs
    â”œâ”€â”€ Public Trust Impact: Alert fatigue potential
    â”œâ”€â”€ Seasonal Patterns: When false alerts occur
    â””â”€â”€ Pollutant Attribution: Which pollutants cause false alerts
```

#### False Negative Analysis *(CRITICAL FOR PUBLIC HEALTH)*
```
For each model M in [SimpleAverage, RidgeRegression]:
â””â”€â”€ False Negative Characterization
    â”œâ”€â”€ Rate: FN / (FN + TP) - TARGET: <10%
    â”œâ”€â”€ Health Impact: Missed protection opportunities
    â”œâ”€â”€ Severity Analysis: AQI levels of missed warnings
    â”œâ”€â”€ Temporal Patterns: When warnings are missed
    â”œâ”€â”€ Geographic Patterns: Cities with higher miss rates
    â””â”€â”€ Pollutant Attribution: Which pollutants are under-predicted
```

---

## ðŸŒ Continental Evaluation Strategy

### Standardized Benchmark Comparison

#### Europe (20 cities)
- **Benchmarks**: EEA data, CAMS forecasts, National networks
- **Ground Truth**: EEA monitoring stations
- **Standard**: European EAQI (1-6 scale)
- **Focus**: Cross-border pollution events, heating season impacts

#### North America (20 cities)
- **Benchmarks**: EPA AirNow, Environment Canada, NOAA forecasts
- **Ground Truth**: Government monitoring stations
- **Standards**: EPA AQI, Canadian AQHI, Mexican IMECA
- **Focus**: Wildfire events, industrial pollution, seasonal variations

#### Asia (20 cities)
- **Benchmarks**: WAQI aggregated data, NASA satellite estimates
- **Ground Truth**: National government monitoring (CPCB, China MEE, etc.)
- **Standards**: Indian National AQI, Chinese AQI, Thai AQI, etc.
- **Focus**: Monsoon effects, dust storms, industrial activity

#### Africa (20 cities)
- **Benchmarks**: NASA MODIS satellite, Research networks
- **Ground Truth**: WHO data, Limited government monitoring
- **Standard**: WHO Guidelines adaptation
- **Focus**: Saharan dust, seasonal burning, data availability challenges

#### South America (20 cities)
- **Benchmarks**: NASA satellite, Regional research networks
- **Ground Truth**: National government monitoring where available
- **Standards**: EPA adaptations, Chilean ICA
- **Focus**: Biomass burning, ENSO effects, altitude impacts

---

## ðŸ“ˆ Evaluation Methodology

### 1. Walk-Forward Validation
```
For each city C and model M:
â”œâ”€â”€ Training Period: Historical data up to validation date
â”œâ”€â”€ Validation Window: Rolling 1-month periods
â”œâ”€â”€ Forecast Horizon: 1-7 days ahead
â”œâ”€â”€ Update Frequency: Weekly model retraining
â””â”€â”€ Evaluation Period: Minimum 6 months per city
```

### 2. Cross-Validation Strategy
- **Temporal Splits**: Respect time series nature of data
- **Seasonal Validation**: Performance across different seasons
- **Geographic Validation**: Model generalization across cities
- **Extreme Event Focus**: Performance during high pollution episodes

### 3. Statistical Significance Testing
- **Paired t-tests**: Model comparison significance
- **Wilcoxon signed-rank**: Non-parametric model comparison
- **Bootstrap confidence intervals**: Metric uncertainty quantification
- **Multiple comparison corrections**: Bonferroni/FDR adjustments

---

## ðŸŽ¯ Evaluation Reporting Framework

### 1. Model Performance Summary
```
Global Performance Report:
â”œâ”€â”€ Executive Summary
â”‚   â”œâ”€â”€ Best performing model overall
â”‚   â”œâ”€â”€ Health warning performance summary
â”‚   â”œâ”€â”€ Continental performance comparison
â”‚   â””â”€â”€ Key recommendations
â”œâ”€â”€ Detailed Results by Continent
â”‚   â”œâ”€â”€ Per-city performance tables
â”‚   â”œâ”€â”€ Benchmark comparison charts
â”‚   â”œâ”€â”€ Health warning confusion matrices
â”‚   â””â”€â”€ Failure mode analysis
â””â”€â”€ Model-Specific Analysis
    â”œâ”€â”€ Simple Average: Baseline performance
    â”œâ”€â”€ Ridge Regression: Optimization benefits
    â””â”€â”€ Future: Gradient Boosting improvements
```

### 2. Health Impact Assessment
```
Public Health Report:
â”œâ”€â”€ Health Warning Effectiveness
â”‚   â”œâ”€â”€ False negative rates by severity
â”‚   â”œâ”€â”€ Missed protection opportunities
â”‚   â”œâ”€â”€ Seasonal vulnerability patterns
â”‚   â””â”€â”€ High-risk population coverage
â”œâ”€â”€ Early Warning Performance
â”‚   â”œâ”€â”€ Lead time analysis (1-7 days)
â”‚   â”œâ”€â”€ Warning cascade effectiveness
â”‚   â”œâ”€â”€ Multi-day episode prediction
â”‚   â””â”€â”€ Uncertainty communication
â””â”€â”€ Regional Health Impact
    â”œâ”€â”€ Population exposure reduction potential
    â”œâ”€â”€ Vulnerable group protection effectiveness
    â”œâ”€â”€ Economic impact of improved warnings
    â””â”€â”€ Public health system integration opportunities
```

---

## ðŸ”„ Future Evaluation Enhancements

### Additional Metrics (To Be Determined)
The evaluation framework will be expanded based on:
- **Stakeholder Feedback**: Input from public health authorities
- **Operational Experience**: Real-world deployment insights
- **Research Developments**: New air quality forecasting metrics
- **Regional Requirements**: Local evaluation preferences

### Potential Additional Metrics
- **Ensemble Diversity Measures**: Disagreement quantification between models
- **Uncertainty Quantification**: Prediction interval coverage and calibration
- **Spatial Coherence**: Cross-city prediction consistency
- **Temporal Stability**: Model performance consistency over time
- **Feature Importance Analysis**: Regional feature contribution assessment
- **Computational Efficiency**: Model runtime and resource requirements

---

## ðŸ“‹ Implementation Priority

### Phase 4 (Current Implementation)
1. âœ… **Core Metrics**: MAE, RMSE, RÂ² for individual pollutants
2. âœ… **AQI Metrics**: Category accuracy and health warning performance
3. âœ… **Health Analysis**: False positive/negative characterization
4. âœ… **Simple Models**: Simple Average and Ridge Regression evaluation

### Phase 5 (Future Enhancement)
1. ðŸ”„ **Advanced Models**: Gradient Boosting integration and evaluation
2. ðŸ”„ **Extended Metrics**: Additional evaluation measures based on stakeholder input
3. ðŸ”„ **Real-time Evaluation**: Live performance monitoring and alerting
4. ðŸ”„ **Comparative Studies**: Academic publication and peer review

---

**Document Status**: Phase 4 Ready - Core Evaluation Framework Defined
**Last Updated**: 2025-09-10
**Next Review**: Upon completion of Phase 4 implementation
**Contact**: Global Air Quality Forecasting Evaluation Team
