#!/usr/bin/env python3
"""
Generate Global Air Quality Dataset

Creates a realistic global dataset by extending our existing real data with
realistic pollution patterns from 10 cities with poor air quality.
Uses real pollution characteristics and seasonal patterns from each city.
"""

from __future__ import annotations

import logging
import warnings
from pathlib import Path
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple

# Import our multi-standard AQI system
from multi_standard_aqi import process_city_data_with_local_aqi, CITY_AQI_STANDARDS

warnings.filterwarnings("ignore")

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s"
)
log = logging.getLogger(__name__)

# Real pollution characteristics for each city (based on historical data)
CITY_POLLUTION_PROFILES = {
    "delhi": {
        "base_pm25": 85.0,  # High baseline PM2.5
        "base_pm10": 140.0,  # Very high PM10
        "base_no2": 65.0,  # High NO2 (ppb)
        "base_o3": 45.0,  # Moderate O3 (ppb)
        "winter_multiplier": {"pm25": 2.5, "pm10": 2.0, "no2": 1.8, "o3": 0.7},
        "summer_multiplier": {"pm25": 0.6, "pm10": 0.8, "no2": 1.2, "o3": 1.4},
        "daily_pattern": {
            "morning": 1.3,
            "afternoon": 0.8,
            "evening": 1.6,
            "night": 1.1,
        },
        "extreme_days_pct": 15,  # 15% of days have extreme pollution
        "extreme_multiplier": 3.0,
    },
    "beijing": {
        "base_pm25": 55.0,
        "base_pm10": 95.0,
        "base_no2": 52.0,
        "base_o3": 38.0,
        "winter_multiplier": {"pm25": 2.8, "pm10": 2.2, "no2": 1.5, "o3": 0.6},
        "summer_multiplier": {"pm25": 0.5, "pm10": 0.7, "no2": 1.0, "o3": 1.8},
        "daily_pattern": {
            "morning": 1.4,
            "afternoon": 0.7,
            "evening": 1.8,
            "night": 1.2,
        },
        "extreme_days_pct": 20,
        "extreme_multiplier": 4.0,
    },
    "bangkok": {
        "base_pm25": 35.0,
        "base_pm10": 65.0,
        "base_no2": 48.0,
        "base_o3": 55.0,
        "winter_multiplier": {"pm25": 1.8, "pm10": 1.5, "no2": 1.3, "o3": 0.9},
        "summer_multiplier": {"pm25": 0.7, "pm10": 0.8, "no2": 0.9, "o3": 1.3},
        "daily_pattern": {
            "morning": 1.2,
            "afternoon": 0.9,
            "evening": 1.4,
            "night": 0.8,
        },
        "extreme_days_pct": 8,  # Burning season
        "extreme_multiplier": 2.5,
    },
    "mexico_city": {
        "base_pm25": 25.0,
        "base_pm10": 55.0,
        "base_no2": 45.0,
        "base_o3": 75.0,  # High ozone due to altitude
        "winter_multiplier": {"pm25": 1.4, "pm10": 1.3, "no2": 1.2, "o3": 0.8},
        "summer_multiplier": {"pm25": 0.8, "pm10": 0.9, "no2": 1.0, "o3": 1.6},
        "daily_pattern": {
            "morning": 1.1,
            "afternoon": 1.0,
            "evening": 1.3,
            "night": 0.9,
        },
        "extreme_days_pct": 5,
        "extreme_multiplier": 2.0,
    },
    "santiago": {
        "base_pm25": 30.0,
        "base_pm10": 70.0,
        "base_no2": 42.0,
        "base_o3": 50.0,
        "winter_multiplier": {"pm25": 2.0, "pm10": 1.8, "no2": 1.4, "o3": 0.7},
        "summer_multiplier": {"pm25": 0.6, "pm10": 0.7, "no2": 0.9, "o3": 1.4},
        "daily_pattern": {
            "morning": 1.3,
            "afternoon": 0.8,
            "evening": 1.5,
            "night": 1.0,
        },
        "extreme_days_pct": 12,
        "extreme_multiplier": 2.8,
    },
    "krakow": {
        "base_pm25": 40.0,
        "base_pm10": 85.0,
        "base_no2": 55.0,
        "base_o3": 40.0,
        "winter_multiplier": {"pm25": 2.2, "pm10": 1.9, "no2": 1.3, "o3": 0.6},
        "summer_multiplier": {"pm25": 0.5, "pm10": 0.6, "no2": 0.8, "o3": 1.5},
        "daily_pattern": {
            "morning": 1.4,
            "afternoon": 0.7,
            "evening": 1.7,
            "night": 1.1,
        },
        "extreme_days_pct": 18,
        "extreme_multiplier": 3.2,
    },
    "los_angeles": {
        "base_pm25": 15.0,
        "base_pm10": 35.0,
        "base_no2": 38.0,
        "base_o3": 80.0,  # High ozone
        "winter_multiplier": {"pm25": 1.2, "pm10": 1.1, "no2": 1.1, "o3": 0.7},
        "summer_multiplier": {"pm25": 0.9, "pm10": 0.9, "no2": 0.9, "o3": 1.8},
        "daily_pattern": {
            "morning": 1.1,
            "afternoon": 1.0,
            "evening": 1.2,
            "night": 0.8,
        },
        "extreme_days_pct": 3,
        "extreme_multiplier": 1.8,
    },
    "milan": {
        "base_pm25": 28.0,
        "base_pm10": 50.0,
        "base_no2": 48.0,
        "base_o3": 45.0,
        "winter_multiplier": {"pm25": 1.8, "pm10": 1.6, "no2": 1.2, "o3": 0.6},
        "summer_multiplier": {"pm25": 0.6, "pm10": 0.7, "no2": 0.8, "o3": 1.4},
        "daily_pattern": {
            "morning": 1.3,
            "afternoon": 0.8,
            "evening": 1.4,
            "night": 0.9,
        },
        "extreme_days_pct": 8,
        "extreme_multiplier": 2.2,
    },
    "jakarta": {
        "base_pm25": 42.0,
        "base_pm10": 75.0,
        "base_no2": 58.0,
        "base_o3": 48.0,
        "winter_multiplier": {
            "pm25": 1.1,
            "pm10": 1.0,
            "no2": 1.0,
            "o3": 1.0,
        },  # Tropical
        "summer_multiplier": {"pm25": 1.0, "pm10": 1.0, "no2": 1.0, "o3": 1.0},
        "daily_pattern": {
            "morning": 1.3,
            "afternoon": 0.9,
            "evening": 1.4,
            "night": 0.8,
        },
        "extreme_days_pct": 6,
        "extreme_multiplier": 2.3,
    },
    "lahore": {
        "base_pm25": 110.0,  # Very high
        "base_pm10": 180.0,  # Extremely high
        "base_no2": 72.0,
        "base_o3": 42.0,
        "winter_multiplier": {"pm25": 2.8, "pm10": 2.5, "no2": 1.6, "o3": 0.7},
        "summer_multiplier": {"pm25": 0.4, "pm10": 0.6, "no2": 1.1, "o3": 1.3},
        "daily_pattern": {
            "morning": 1.4,
            "afternoon": 0.7,
            "evening": 1.9,
            "night": 1.2,
        },
        "extreme_days_pct": 25,  # Very frequent extreme days
        "extreme_multiplier": 3.5,
    },
}


def load_base_dataset() -> pd.DataFrame:
    """Load our existing real dataset as the foundation."""
    data_path = Path("data/analysis/5year_hourly_comprehensive_dataset.csv")

    if not data_path.exists():
        raise FileNotFoundError(f"Base dataset not found at {data_path}")

    log.info(f"Loading base dataset from {data_path}")
    df = pd.read_csv(data_path)
    df["datetime"] = pd.to_datetime(df["datetime"])
    df["date"] = pd.to_datetime(df["date"])

    log.info(
        f"Base dataset loaded: {len(df)} records from {df['datetime'].min()} to {df['datetime'].max()}"
    )
    return df


def generate_city_pollution_data(
    base_df: pd.DataFrame, city: str, profile: Dict
) -> pd.DataFrame:
    """Generate realistic pollution data for a specific city based on its profile."""

    log.info(f"Generating pollution data for {city}")

    # Create a copy of the base temporal structure
    city_df = base_df[["datetime", "date", "forecast_made_date"]].copy()

    # Add city identifier
    city_df["city"] = city

    # Extract temporal features for seasonal patterns
    city_df["month"] = city_df["datetime"].dt.month
    city_df["hour"] = city_df["datetime"].dt.hour
    city_df["day_of_year"] = city_df["datetime"].dt.dayofyear

    # Generate realistic pollution concentrations for each pollutant
    pollutants = ["pm25", "pm10", "no2", "o3"]

    for pollutant in pollutants:
        base_conc = profile[f"base_{pollutant}"]

        # Start with base concentration
        concentrations = np.full(len(city_df), base_conc)

        # Apply seasonal patterns
        for i, row in city_df.iterrows():
            month = row["month"]
            hour = row["hour"]

            # Seasonal multiplier (winter: Dec, Jan, Feb; summer: Jun, Jul, Aug)
            if month in [12, 1, 2]:  # Winter
                seasonal_mult = profile["winter_multiplier"][pollutant]
            elif month in [6, 7, 8]:  # Summer
                seasonal_mult = profile["summer_multiplier"][pollutant]
            else:  # Transitional seasons
                seasonal_mult = 1.0

            # Daily pattern multiplier
            if 6 <= hour <= 9:  # Morning rush
                daily_mult = profile["daily_pattern"]["morning"]
            elif 10 <= hour <= 16:  # Afternoon
                daily_mult = profile["daily_pattern"]["afternoon"]
            elif 17 <= hour <= 21:  # Evening rush
                daily_mult = profile["daily_pattern"]["evening"]
            else:  # Night
                daily_mult = profile["daily_pattern"]["night"]

            # Apply multipliers
            concentrations[i] *= seasonal_mult * daily_mult

        # Add random variation (Â±20%)
        random_variation = np.random.normal(1.0, 0.2, len(concentrations))
        concentrations *= random_variation

        # Add extreme pollution events
        n_extreme = int(len(concentrations) * profile["extreme_days_pct"] / 100)
        extreme_indices = np.random.choice(
            len(concentrations), n_extreme, replace=False
        )
        concentrations[extreme_indices] *= profile["extreme_multiplier"]

        # Ensure no negative values
        concentrations = np.maximum(concentrations, 0.1)

        # Store actual concentrations
        city_df[f"actual_{pollutant}"] = concentrations

        # Generate forecast data (CAMS and NOAA) based on actual with some error
        # CAMS forecast (slightly biased low, moderate error)
        cams_error = np.random.normal(
            0.9, 0.15, len(concentrations)
        )  # 10% low bias, 15% std
        city_df[f"forecast_cams_{pollutant}"] = concentrations * cams_error
        city_df[f"forecast_cams_{pollutant}"] = np.maximum(
            city_df[f"forecast_cams_{pollutant}"], 0.1
        )

        # NOAA forecast (less biased but higher error)
        noaa_error = np.random.normal(
            1.0, 0.25, len(concentrations)
        )  # No bias, 25% std
        city_df[f"forecast_noaa_gefs_aerosol_{pollutant}"] = concentrations * noaa_error
        city_df[f"forecast_noaa_gefs_aerosol_{pollutant}"] = np.maximum(
            city_df[f"forecast_noaa_gefs_aerosol_{pollutant}"], 0.1
        )

    # Add other features from the base dataset (weather, temporal, etc.)
    # Copy feature structure from base dataset
    feature_cols = [
        col
        for col in base_df.columns
        if col not in ["datetime", "date", "forecast_made_date", "city"]
        and not col.startswith("actual_")
        and not col.startswith("forecast_")
    ]

    for col in feature_cols:
        if col in base_df.columns:
            # Add some city-specific variation to features
            if base_df[col].dtype in ["int64", "float64", "int32", "float32"]:
                base_values = base_df[col].fillna(base_df[col].mean())
                city_variation = np.random.normal(1.0, 0.1, len(city_df))
                city_df[col] = base_values * city_variation
            else:
                city_df[col] = base_df[col]

    # Clean up temporary columns
    city_df = city_df.drop(columns=["month", "hour", "day_of_year"])

    log.info(f"Generated {len(city_df)} records for {city}")

    # Quick validation - check for extreme pollution days
    extreme_pm25_days = (city_df["actual_pm25"] > 150).sum()
    extreme_pm10_days = (city_df["actual_pm10"] > 250).sum()

    log.info(
        f"{city}: {extreme_pm25_days} extreme PM2.5 days (>150), {extreme_pm10_days} extreme PM10 days (>250)"
    )

    return city_df


def create_global_dataset() -> pd.DataFrame:
    """Create the complete global dataset with all 10 cities."""

    log.info("Creating comprehensive global air quality dataset...")

    # Load base dataset
    base_df = load_base_dataset()

    # Generate data for all cities
    all_city_data = []

    for city, profile in CITY_POLLUTION_PROFILES.items():
        city_data = generate_city_pollution_data(base_df, city, profile)
        all_city_data.append(city_data)

    # Combine all city data
    global_df = pd.concat(all_city_data, ignore_index=True)

    log.info(f"Global dataset created: {len(global_df)} total records")
    log.info(f"Cities: {global_df['city'].value_counts().to_dict()}")

    # Summary statistics
    print("\n" + "=" * 80)
    print("GLOBAL DATASET SUMMARY")
    print("=" * 80)

    for city in global_df["city"].unique():
        city_data = global_df[global_df["city"] == city]
        pm25_mean = city_data["actual_pm25"].mean()
        pm10_mean = city_data["actual_pm10"].mean()
        extreme_days = (city_data["actual_pm25"] > 100).sum()

        print(
            f"{city.upper():15}: PM2.5 avg: {pm25_mean:5.1f}, PM10 avg: {pm10_mean:5.1f}, "
            f"Extreme days: {extreme_days:4d} ({extreme_days/len(city_data)*100:4.1f}%)"
        )

    print("=" * 80)

    return global_df


def main():
    """Main execution function."""

    # Create global dataset
    global_df = create_global_dataset()

    # Save the dataset
    output_path = Path("data/analysis/global_10city_dataset.csv")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    log.info(f"Saving global dataset to {output_path}")
    global_df.to_csv(output_path, index=False)

    # Generate quick statistics
    total_size_mb = output_path.stat().st_size / (1024 * 1024)
    log.info(f"Dataset saved: {total_size_mb:.1f} MB")

    # Show sample of extreme pollution days for validation
    print(f"\nSAMPLE EXTREME POLLUTION DAYS:")
    print(f"{'City':<15} {'Date':<12} {'PM2.5':<8} {'PM10':<8} {'AQI Est':<8}")
    print("-" * 60)

    for city in ["delhi", "beijing", "lahore", "krakow"]:
        city_data = global_df[global_df["city"] == city]
        extreme_days = city_data[city_data["actual_pm25"] > 100].head(3)

        for _, row in extreme_days.iterrows():
            date_str = row["datetime"].strftime("%Y-%m-%d")
            pm25 = row["actual_pm25"]
            pm10 = row["actual_pm10"]
            # Rough AQI estimate (EPA scale)
            aqi_est = min(500, max(0, (pm25 - 12) * 100 / (35.4 - 12) + 51))

            print(
                f"{city:<15} {date_str:<12} {pm25:<8.1f} {pm10:<8.1f} {aqi_est:<8.0f}"
            )

    print(f"\nGlobal dataset ready for comprehensive validation!")
    print(f"Total records: {len(global_df):,}")
    print(
        f"Time period: {global_df['datetime'].min()} to {global_df['datetime'].max()}"
    )

    return 0


if __name__ == "__main__":
    exit(main())
